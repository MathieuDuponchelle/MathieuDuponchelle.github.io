fragment_downloaded_cb({"url": "2018-02-15-Python-Elements-2.html#page-description", "fragment": "In the previous post I presented a test audio source and used it to illustrate basic gst python concepts and present the GstBase.BaseSrc base class. \nThis post assumes familiarity with said concepts it will expand on some more advanced topics such as caps negotiation present another base class GstBase.BaseTransform and a useful object GstAudio.AudioConverter. \nThe example element will accept any sort of audio input on its sink pad and output a waveform as a series of raw video frames. The output framerate and resolution will not be fixed and instead negotiated with downstream elements. \nThe following video was generated with \nThis is the video most related to python plotting I could find please don t stone me \nAt the moment of writing the master branches from both pygobject and gstreamer need to be installed. \nThe python libraries we will use for the purpose of plotting are matplotlib and numpy_ringbuffer to help decoupling our input and output. Both are installable with pip \nYou can test the element as follows \nFor our audio test source example I chose to implement the simplest form of caps negotiation fixed negotiation. The element stated that it would output a specific format on its source pad and its base classes handled the rest. \nFor this example however the element will accept a wide range of input formats and propose a wide range of output formats as well \nLet s see what gst inspect tells us about its pad templates here \nThe element states that it can accept any audio format with any rate and any number of channels the only restriction that we place is that samples should be interleaved. \nOn the output side once again we place a single restriction and state that the element will only be able to output ARGB data this because ARGB is the only alpha capable pixel format the matplotlib API we will use proposes. \nWhen inheriting from Gst.Element negotiation is implemented by receiving and sending events and queries on the pads of the element. \nHowever most if not all other GStreamer base classes take care of this aspect and instead let their subclasses optionally implement a set of virtual methods adapted to the base class purpose. \nIn the case of BaseTransform the base class assumes that input and output caps will depend on each other imagine an element that would crop a video by a set number of pixels it is easy to see that the resolution of the output will depend on that of the input. \nWith that in mind the virtual method we need to expose is the aptly named do_transform_caps \nIn our case there is no dependency between input and output receiving audio with a given sample format will not cause it to output video in a different resolution. \nConsequently when asked to transform the caps of the sink pad we simply need to return the template of the source pad potentially intersected with the optional filter argument this parameter is useful for reducing the complexity of the overall negotiation process \nAn example of an element where input and output are interdependent is videocrop. \nImplementing this virtual method is enough to make negotiation succeed if upstream and downstream elements have compatible capabilities but if for example downstream also accepts a wide range of resolutions the default behaviour of the base class will be to pick the smallest possible resolution. \nThis behaviour is known as fixating the caps and BaseTransform exposes a virtual method to let the subclass pick a sane default value in such cases \nWe do not have a preferred input format and as a consequence we use the default caps.fixate implementation. \nHowever if for example the element is offered to output its full resolution range we are going to try and pick the resolution closest to our preferred default this is what the calls to fixate_field_nearest_int achieve. \nThis will have no effect if the field is already fixated to a specific value. \nIf the field was set to a range not containing our preferred value fixating would result in picking the allowed value closest to it for example given our preferred width and the allowed range the final value of the field would be \nAll that remains to do is for the element to initialize its state based on the result of the caps negotiation \nThe meat of that function is omitted due to its sausage factory nature amongst other things it creates a matplotlib figure with the correct size set_size_inches is one of the worst API I ve ever seen initializes some counters a ringbuffer etc \nAs I decided to support any sample format as the input the most straightforward and reasonably performant approach is to use GstAudio.AudioConverter \nWe initialize a converter based on our input format as explained above this is best done in do_set_caps \nBy setting the required output format to GstAudio.AudioFormat.S32 we ensure that the endianness of the converted samples will be the native endianness of the platform the code runs on which means that we can in turn cast our memoryview to i memoryview.cast doesn t let its user select an endianness \nThe best alternative I m aware of is possibly to use python s struct module in combination with the pack and unpack functions exposed on GstAudio.AudioFormatInfo however those are not yet available in the python bindings. \nThe initial version of this element only implemented do_transform and simply plotted one output buffer per input buffer. This produced a kaleidoscopic effect and slaved the framerate to samplerate samplesperbuffer. \nBaseTransform exposes a virtual method that allows producing to N output buffers per buffer instead do_generate_output \nWhen a new buffer is chained on the sink pad do_generate_output is called repeatedly as long as it returns Gst.FlowReturn.OK and a buffer thanks to that we can fill our ringbuffer and only return a frame once we have processed enough new samples to reach our next time. Conversely we can produce multiple frames if the size of the input buffer warrants it. \nHere again the rest of the function is made up of implementation details an important point to note is that we still expose do_transform as BaseTransform assumes otherwise that the element will operate in passthrough mode which obviously creates some interesting problems. \nSome improvements could be made to this element \nIt could instead of averaging channels use one matplotlib figure per channel and overlap them to provide an output similar to audacity. This would however introduce a dependency between input and output formats \nStyling is hardcoded properties such as transparency line color line width etc.. could be exposed. \nmatplotlib is atrociously slow and not really meant for real time usage. Some effort was made to optimize its usage blit thinning_factor however performance is still disappointing. vispy might be an alternative worth exploring. \nOn a more positive note it should be noted that while our previous element had a more capable equivalent audiotestsrc this element does not really have one and its implementation is satisfyingly concise \nI don t have an idea yet for the next post in the series the most interesting scientific python packages I can think of are machine learning ones such as tensorflow but I have no experience with these ideally a new post should also explore a different base class GstAggregator GstBaseSink \nSuggestions welcome \n"});